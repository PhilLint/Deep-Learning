# UvA Deep Learning Course Practical Assignments

## Assignment 1: MLP & CNNs

Deriving theoretical properties and (re-)implementing those. Multilayer Perceptron theoretical backpropagation derivations with respective implementations in [Numpy](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_1/code/mlp_numpy.py) and [Pytorch](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_1/code/mlp_pytorch.py).
Custom Batch Normalization implementation in [Pytorch](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_1/code/custom_batchnorm.py). 
Implementation of a given VGG Convolutional Neural Net architecture using [Pytorch](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_1/code/convnet_pytorch.py), which I did not originally submit due to time constraints but reimplemented as of 2021. 
Theoretical derivations together with all results worth reporting from the experiments are gathered in [Assignment 1](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_1/Deep_Learning_Assignment_1_philipp_lintl.pdf) according to the exercises of the [Assignment sheet](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_1/assignment_1.pdf)

## Assignment 2 RNNs and Graph Neural Nets

Theoretical questions and derivations on Recurrent Neural Nets and especially LSTMs. [Implementation](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_2/part1/vanilla_rnn.py) of Vanilla RNN applied on palindrome prediction. [Implementation](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_2/part1/lstm.py) of the LSTM. The [Report](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_2/Deep_Learning_Assignment_2_lintl.pdf) includes theoretical derivations and answers to questions regarding RNNs, LSTMs and Graph Neural Nets, which have not been implemented but only discussed theoretically according to [Assignment Sheet](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_2/assignment_2.pdf)

## Assignment 3 Deep Generative Models
Three Generative approaches, VAE, GANs and Normalizing Flows were discussed, implemented and compared on MNIST data.

First the Variational Autoencoder was thoroughly theoretically discussed and [implemented](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_3/templates/a3_vae_template.py). Next Generative Adversarial Networks were [implemented](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_3/templates/a3_gan_template.py). Not subject to the original project I reimplemented the Normalizing Flow part [here](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_3/templates/a3_nf_template.py). The [Report](https://github.com/PhilLint/Deep-Learning/blob/master/assignment_3/Deep_Learning_Assignment_3_Lintl.pdf)

## 2021
# TBD
Rerun experiments that were reimplemented and add in separate short notes. 
